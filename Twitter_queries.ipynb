{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "import urllib.parse\n",
    "import config\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main(query=query, fields=fields, print_yes=True):\n",
    "    \"\"\"\n",
    "    This function defines the bearer token, the query url\n",
    "    and headers and returns the API response in JSON.\n",
    "    \n",
    "    Inputs:\n",
    "    query = String variable. This is the main query specifying \n",
    "            the Query Parameters. For example: from:elonmusk, lang:en\n",
    "            -is:retweet, max_results=100. Space separated list.\n",
    "            If it is a retweet the function replaces # with %23 and\n",
    "            spaces will be replaced by %20 (URL encoding purposes).\n",
    "    tweet_fields = String variable. This defines what Response\n",
    "            Fields we want for the tweets. For example: author_id, \n",
    "            public_metrics, created_at, geo, id. Comma separated list\n",
    "            without spaces.\n",
    "    \n",
    "    Returns:\n",
    "    json response object containing the API response\n",
    "    \"\"\"\n",
    "    #Load the bearer token from the config.py file\n",
    "    bearer_token = config.bearer_token\n",
    "    #Create the url and headers as the inputs for the API request. Keep in mind URL encoding\n",
    "    query = urllib.parse.quote(query)\n",
    "    url = \"https://api.twitter.com/2/tweets/search/recent?query={}&{}\".format(\n",
    "        query, fields)\n",
    "    if print_yes == True:\n",
    "        print(url)\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    \n",
    "    #Connect to the Twitter API endpoint using the query url and headers\n",
    "    response = requests.request(\"GET\", url, headers=headers)\n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "\n",
    "    if print_yes == True:\n",
    "        print(json.dumps(response.json(), indent=4, sort_keys=True))\n",
    "    \n",
    "    return response.json(), url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "query = '#fintech lang:en -is:retweet'\n",
    "fields = \"tweet.fields=author_id,created_at,public_metrics\"\\\n",
    "         \"&expansions=author_id\"\\\n",
    "         \"&user.fields=username,public_metrics,description\"\\\n",
    "         \"&next_token=b26v89c19zqg8o3fosnsxakj8cs5etp98ks9zbaha2av1\"\n",
    "\n",
    "\n",
    "result, url = main(query, fields, print_yes = False)\n",
    "\n",
    "# Get the next token:\n",
    "#next_token = result['meta']['next_token']\n",
    "#next_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.json_normalize(result['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = '/Users/alan/Desktop/Thesis_local/Datasets'\n",
    "df.to_csv('Datasets/test.csv')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
